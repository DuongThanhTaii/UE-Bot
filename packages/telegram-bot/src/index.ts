import 'dotenv/config';
import { Bot, Context } from 'grammy';
import Groq from 'groq-sdk';

// Validate environment variables
const TELEGRAM_BOT_TOKEN = process.env.TELEGRAM_BOT_TOKEN;
const GROQ_API_KEY = process.env.GROQ_API_KEY;

if (!TELEGRAM_BOT_TOKEN) {
  throw new Error('TELEGRAM_BOT_TOKEN is required');
}

if (!GROQ_API_KEY) {
  throw new Error('GROQ_API_KEY is required');
}

// Initialize Groq client
const groq = new Groq({
  apiKey: GROQ_API_KEY,
});

// Initialize Telegram bot
const bot = new Bot(TELEGRAM_BOT_TOKEN);

// Store conversation history per user (simple in-memory)
const conversations = new Map<number, Array<{ role: 'user' | 'assistant'; content: string }>>();

// System prompt - keep it minimal to avoid context overflow
const SYSTEM_PROMPT = `B·∫°n l√† UE Bot, m·ªôt tr·ª£ l√Ω AI th√¥ng minh c·ªßa ƒê·∫°i h·ªçc S∆∞ ph·∫°m TP.HCM.
H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn, h·ªØu √≠ch v√† th√¢n thi·ªán b·∫±ng ti·∫øng Vi·ªát.`;

// Get AI response from Groq
async function getAIResponse(userId: number, message: string): Promise<string> {
  // Get or create conversation history
  let history = conversations.get(userId) || [];

  // Add user message to history
  history.push({ role: 'user', content: message });

  // Keep only last 5 messages to avoid context overflow
  if (history.length > 10) {
    history = history.slice(-10);
  }

  try {
    const completion = await groq.chat.completions.create({
      model: 'llama-3.1-8b-instant',
      messages: [{ role: 'system', content: SYSTEM_PROMPT }, ...history],
      max_tokens: 1024,
      temperature: 0.7,
    });

    const reply =
      completion.choices[0]?.message?.content || 'Xin l·ªói, t√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi l√∫c n√†y.';

    // Add assistant response to history
    history.push({ role: 'assistant', content: reply });
    conversations.set(userId, history);

    return reply;
  } catch (error: any) {
    console.error('Groq API error:', error.message);

    // Clear history on error to reset
    if (error.message?.includes('context') || error.message?.includes('overflow')) {
      conversations.delete(userId);
      return 'Xin l·ªói, cu·ªôc h·ªôi tho·∫°i qu√° d√†i. H√£y b·∫Øt ƒë·∫ßu l·∫°i nh√©!';
    }

    return `Xin l·ªói, c√≥ l·ªói x·∫£y ra: ${error.message}`;
  }
}

// Handle /start command
bot.command('start', async (ctx: Context) => {
  const userId = ctx.from?.id;
  if (userId) {
    conversations.delete(userId); // Reset conversation
  }
  await ctx.reply(
    'ü§ñ Xin ch√†o! T√¥i l√† UE Bot - Tr·ª£ l√Ω AI c·ªßa ƒê·∫°i h·ªçc S∆∞ ph·∫°m TP.HCM.\n\n' +
      'B·∫°n c√≥ th·ªÉ h·ªèi t√¥i b·∫•t c·ª© ƒëi·ªÅu g√¨!\n\n' +
      'L·ªánh:\n' +
      '/start - B·∫Øt ƒë·∫ßu l·∫°i cu·ªôc tr√≤ chuy·ªán\n' +
      '/clear - X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i'
  );
});

// Handle /clear command
bot.command('clear', async (ctx: Context) => {
  const userId = ctx.from?.id;
  if (userId) {
    conversations.delete(userId);
  }
  await ctx.reply('‚úÖ ƒê√£ x√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i. H√£y b·∫Øt ƒë·∫ßu cu·ªôc tr√≤ chuy·ªán m·ªõi!');
});

// Handle all text messages
bot.on('message:text', async (ctx: Context) => {
  const userId = ctx.from?.id;
  const message = ctx.message?.text;

  if (!userId || !message) return;

  // Show typing indicator
  await ctx.replyWithChatAction('typing');

  // Get AI response
  const response = await getAIResponse(userId, message);

  // Reply to user
  await ctx.reply(response, {
    reply_to_message_id: ctx.message?.message_id,
  });
});

// Error handling
bot.catch((err) => {
  console.error('Bot error:', err);
});

// Start the bot
console.log('ü§ñ Starting UE Bot...');
bot.start({
  onStart: (botInfo) => {
    console.log(`‚úÖ Bot started as @${botInfo.username}`);
    console.log('üì± Send a message to the bot to test!');
  },
});
